---
title: "Processing simulation output"
output: github_document
bibliography: ../manuscript/manuscript/asreview.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rjson)
library(tidyverse)
library(knitr)
library(flextable)
library(officer)
library(xtable)
set.seed(42)
```

This directory stores all files used to extract figures and statistics from the simulation study output.
The directory contains the following:

- `extract_plots.ipynb`, a jupyter notebook producing recall curves from the simulation output (Figure 1 and 2 in the manuscript)
- `extract_results.ipynb`, a jupyter notebook extracting `.json` files containing statistics from the `.h5` simulation output (WSS, RRF, ATD in table 2, 3, and 4 in the manuscript)
- `one_seed`, containing all plots and `.json` statistics files produced by the two jupyter notebooks above. The plots are used in the manuscript, the data are further processed by this readme into tables before they are manuscript-ready.
- `README.Rmd` containing R-code to transform the `.json` files into readable tables for the manuscript.
- `output` contains the abovementioned tables, stored as `.RDS` files.  
- the `datastats.RDS` is used in the analyses to compute adjusted ATD values (see code below)

# Requirements
Extracing data from the simulation output requires having several packages installed, like ASReview version 0.9.3 [@ASReview2020]. All these requirements are listed in the `requirements.txt` file. If you've already installed this file in the `simulation_study` step, please skip this. If not, you can run the following in your terminal to install all requirements: 

```{bash, eval = FALSE}
pip install -r ../simulation_study/requirements.txt
```

Additionally, to create the plots and statistics in the manuscript you will need to install a specific branch of the asreview visualization package. Run the following in your terminal: 

```{bash, eval = FALSE}
# clone visualization package from GitHub
git clone https://github.com/GerbrichFerdinands/asreview-thesis-visualization.git
```

And then, within the newly created directory, the following:

```{bash, eval = FALSE}
# install visualization package 
pip install . 
```

# Reproduce data extraction
To reproduce the results, follow the steps below. If you do not want to download the raw simulation output, start at step 3:

1. Run all code in the `extract_plots.ipynb` notebook to create all plots. This requires having the raw simulation data, to be found on the OSF (https://osf.io/7mr2g/ and https://osf.io/ag2xp/). Note that you will need to adjust the paths to where you've stored the simulation output on your local computer. Also, note that creating figures can take quite some time, depending on your computer. Mine took from 30 minutes to 5 hours per figure The final figures can be found in the `one_seed/plots` directory. 
2. Run all code in the `extract_results.ipynb` to extract the metrics WSS, RRF and ATD from the raw simulation data. Note that you will need to adjust the paths to where you've stored the simulation output on your local computer. Also, note that extracting all results will take quite some time, depending on your computer. Mine took 48 hours. The results are stored in the `one_seed/plots` directory. 
3. Follow the preprocessing steps in the `README.Rmd` files to create tables for in the manuscript, stored in the `output` directory. 

## Define functions for reading simulation output 
```{r}
data <- readRDS("../simulation_study/R/00_datasets.RDS")
models <-c("BCTD", "LCDD", "LCTD", "RCDD", "RCTD", "SCDD", "SCTD")
names(models) <- c("NB + TF-IDF", "LR + D2V", "LR + TF-IDF", "RF + D2V", "RF + TF-IDF", "SVM + D2V", "SVM + TF-IDF" )

# function that reads results for all 15 runs at once (all.json files)
read_results <- function(m){
   files = list.files(paste0("one_seed/statistics/", m), pattern = "all.json", recursive = TRUE)
  # names of the files are the data
  names(files) <- str_split(files, "/", simplify = TRUE)[,1]
  # read data
  dat <- lapply(files, function(x) fromJSON(file = paste0("one_seed/statistics/", m, "/", x)))
  
  # extract wss, rrf, and loss
  dat <- map(dat, `[`, c("wss", "rrf", "loss"))

  # transorm into dataframe
  dat <- map_dfr(dat, ~ as.data.frame(.x), .id = "dataset")
  
  # add model name
  dat <- dat %>% 
    mutate(model = names(models[models == m]))

  return(dat)
}

# function for extracting all separate runs (results_x.json files)
read_trials <- function(m){
   files <- list.files(paste0("one_seed/statistics/", m), pattern = "results_", recursive = TRUE, full.names=TRUE)
  # names of the files are the data
  names(files) <- str_split(files, "/", simplify = TRUE)[,4]
  
  # read data
  dat <- lapply(files, function(x) fromJSON(file = x))
  
  # extract wss, rrf, and loss
  dat <- map(dat, `[`, c("wss", "rrf", "loss"))

  # transorm into dataframe
  dat <- map_dfr(dat, ~ as.data.frame(.x), .id = "dataset")
  
  # add model name
  dat <- dat %>% 
    mutate(model = names(models[models == m]))

  return(dat)
}
```


## Load results for 15 separate trials
```{r}
# read all 15 trials separately
runs <- lapply(models, FUN = read_trials)

# all in one dataframe
runs <- do.call("rbind", runs)

# convert loss (ttd) to percentage 
runs$loss <- runs$loss*100

# save results file 
saveRDS(runs, "output/runs.RDS")
```

Compute standarad deviation from the 15 separate trials.
```{r}
# compute standard deviation 
sdruns <- 
  runs %>%
  select(dataset, model, wss.95, rrf.10, loss) %>% 
  group_by(model, dataset) %>%
  summarise(sdwss.95 = sd(wss.95),
            sdrrf.10 = sd(rrf.10),
            sdloss = sd(loss))

saveRDS(sdruns, "output/sdruns.RDS")

```

## Load results as means over all 15 trials  
```{r}
# extract results for all models
# list for models separately
results <- lapply(models, read_results)

# all in one dataframe
results <- do.call("rbind", results)

# convert loss (ttd) to percentage 
results$loss <- results$loss*100

# save results file 
saveRDS(results, "output/results.RDS")
```

Create forest plots for manuscript
```{r, echo = FALSE, results = "asis"}

lower_ci <- function(mean, se, n, conf_level = 0.95){
  lower_ci <- mean - qt(1 - ((1 - conf_level) / 2), n - 1) * se
}
upper_ci <- function(mean, se, n, conf_level = 0.95){
  upper_ci <- mean + qt(1 - ((1 - conf_level) / 2), n - 1) * se
}



order = c("Nudging", "PTSD", "Software", "ACE", "Virus", "Wilson")
# mutate(name = fct_relevel(name, 
#             "north", "north-east", "east", 
#             "south-east", "south", "south-west", 
#             "west", "north-west"))

errorbar_results <- results %>%
  mutate(dataset = stringr::str_to_title(dataset)) 

errorbar_results[errorbar_results["dataset"]=="Ace", "dataset"] <- "ACE"
errorbar_results[errorbar_results["dataset"]=="Ptsd", "dataset"] <- "PTSD"

errorbar_results <- errorbar_results %>%
  mutate(dataset = fct_relevel(factor(dataset), "Nudging", "PTSD", "Software", "ACE", "Virus", "Wilson")) %>%
  select(model, dataset, wss.95, loss, rrf.10) %>%
  group_by(dataset) 

base_data_wss <- errorbar_results %>%
  summarise(smean = mean(wss.95, na.rm=TRUE),
            sd = sd(wss.95, na.rm=TRUE),
            count = n()) %>%
  mutate(se = sd/sqrt(count),
         lower = lower_ci(smean, se, count),
         upper = upper_ci(smean, se, count))

base_data_atd <- errorbar_results %>%
  summarise(smean = mean(loss, na.rm=TRUE),
            sd = sd(loss, na.rm=TRUE),
            count = n()) %>%
  mutate(se = sd/sqrt(count),
         lower = lower_ci(smean, se, count),
         upper = upper_ci(smean, se, count))

base_data_rrf <- errorbar_results %>%
  summarise(smean = mean(rrf.10, na.rm=TRUE),
            sd = sd(rrf.10, na.rm=TRUE),
            count = n()) %>%
  mutate(se = sd/sqrt(count),
         lower = lower_ci(smean, se, count),
         upper = upper_ci(smean, se, count))

```


Create table for manuscript (all means over 15 runs)

```{r, echo = FALSE, results = "asis"}
tabres <- 
  results %>%
  pivot_wider(names_from = dataset, values_from = c("wss.95", "wss.99", "wss.100", "rrf.5", "rrf.10", "rrf.20", "loss"))

# table of mean statistics over all runs 
stabres <- 
tabres %>%
  # select statistics
  select(model,
         starts_with("wss.95"),
         starts_with("rrf.10"), 
         starts_with("loss")) %>%
  # reorder datasets
  select(model,
         ends_with("nudging"),
         ends_with("ptsd"),
         ends_with("software"),
         ends_with("ace"),
         ends_with("virus"),
         ends_with("wilson")
         )

saveRDS(stabres, "output/tabresults.RDS")

knitr::kable(stabres, format = "markdown", digits = 1)
```


Create table for manuscript
```{r}


nicetab <- function(results, statistic){
  test <- results %>% select(model, dataset, all_of(statistic))
  sdname <- paste0("sd", statistic)

  test <- left_join(test, sdruns[,c("model", "dataset", sdname)], by = c("model", "dataset"))
  
  test[,statistic] <- sprintf("%.1f", round(test[,statistic],1)) 
  test[,sdname] <-  sprintf("%.2f", round(test[,sdname],2)) 
  test$tab <- with(test, paste0(test[,statistic], " (", test[,sdname], ")"))
  
  tab <- test %>%
      select(model, dataset, tab) %>%
      pivot_wider(names_from = dataset, values_from = c("tab"))
  
  tab <- tab %>%
    select(model, nudging, ptsd, software, ace, virus, wilson)
  names(tab) <- c("", "Nudging", "PTSD", "Software", "ACE", "Virus", "Wilson")
  return(tab)
}
```

# ATD table

```{r, eval = TRUE}
tabatd <- nicetab(results, "loss") 
tabatd <- tabatd[c(7, 1, 5, 3, 6, 4, 2),]
# add range rows 
mad <- results %>% group_by(dataset) %>% summarise(median = sprintf("%.1f", round(median(loss), 1)), mad = sprintf("%.2f", round(mad(loss), 2)))

mad <- with(mad, paste0(median, " (", mad, ")"))

tabatd <- rbind(tabatd, (c("median (MAD)", mad[c(2:4, 1, 5,6)])))

saveRDS(tabatd, file = "tables/tab2_atd.RDS")

# print(xtable(tabatd, align = c("r", "r", rep("c", 6))), 
#       include.rownames=FALSE, comment = FALSE, booktabs = TRUE, hline.after = c(0,7))
```

```{r}

# titles  (max 15) 
# ATD values for all datasets, on average across seven models with a 95% confidence interval. 
# legends (max 300)


# title alles plot: 
# Performance for all datasets, on average across seven models with a 95% confidence interval. 
# Legend: 
# Performance is expressed by three different metrics: ATD, WSS@95, and RRF@10. All metrics are measured on a scale from 0 to 100. For the ATD holds that the lower the value, the better the performance. For the WSS and RRF holds that the higher the value, the better the perfoormance. 

# Figure titles (max 15 words) and legends (max 300 words) should be provided in the main manuscript, not in the graphic file.
atd_plot <- ggplot(base_data_atd, aes(x=dataset, y = smean)) +
  geom_point(aes(x=dataset, y=smean), size = .5) +
  geom_errorbar(aes(ymin=lower, ymax=upper), width = .25) +
  labs(x = "Dataset", y = "Average Time to Discovery") +
  scale_y_continuous(breaks = seq(0,100,10), limits=c(0,100)) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.background = element_rect(fill = "white", size = 4, colour = "white"),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank(),
    # explicitly set the horizontal lines (or they will disappear too)
    panel.grid.major.x = element_line( size=.05, color="black" )
    ) 

atd_plot

ggsave("figures/atd_values.png", atd_plot)

```

# WSS@95 table 

```{r, eval = TRUE}
tabwss95 <- nicetab(results, "wss.95") 
tabwss95 <- tabwss95[c(7, 1, 5, 3, 6, 4, 2),]
# add range rows 
mad <- results %>% group_by(dataset) %>% summarise(median = sprintf("%.1f", round(median(wss.95), 1)), 
                                                   mad = sprintf("%.2f", round(mad(wss.95), 2)))
# insert mad 
mad <- with(mad, paste0(median, " (", mad, ")"))

tabwss95 <- rbind(tabwss95, (c("median (MAD)", mad[c(2:4, 1, 5,6)])))
# insert N per dataset 
saveRDS(tabwss95, file = "tables/tab3_wss95.RDS")

print(xtable(tabwss95, align = c("r", "r", rep("c", 6))), 
      include.rownames=FALSE, comment = FALSE, booktabs = TRUE, hline.after = c(0,7))
```

```{r}

plottab <- function(results, statistic){
  test <- results %>% select(model, dataset, all_of(statistic))
  sdname <- paste0("sd", statistic)
  test <- left_join(test, sdruns[,c("model", "dataset", sdname)], by = c("model", "dataset"))
  #tab <- tab %>%
    #select(model, nudging, ptsd, software, ace, virus, wilson)
  # names(tab) <- c("", "Nudging", "PTSD", "Software", "ACE", "Virus", "Wilson")

  return(test)
}

mad <- results %>% group_by(dataset) %>% summarise(median = sprintf("%.1f", round(median(wss.95), 1)), 
                                                   mad = sprintf("%.2f", round(mad(wss.95), 2)))


wss_plot <- ggplot(base_data_wss, aes(x=dataset, y = smean)) +
  geom_point(aes(x=dataset, y=smean), size = .5) +
  geom_errorbar(aes(ymin=lower, ymax=upper), width = .25) +
  labs(x = "Dataset", y = "WSS@95") +
  scale_y_continuous(breaks = seq(0,100,10), limits=c(0,100)) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.background = element_rect(fill = "white", size = 4, colour = "white"),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank(),
    # explicitly set the horizontal lines (or they will disappear too)
    panel.grid.major.x = element_line( size=.05, color="black" )
    ) 

wss_plot

ggsave("figures/wss_values.png", wss_plot)

# of met mediaan?? 
```

# RRF@10 table
```{r, eval = TRUE}
tabrrf10 <- nicetab(results, "rrf.10") 

tabrrf10 <- tabrrf10[c(7, 1, 5, 3, 6, 4, 2),]
# add range rows 
mad <- results %>% group_by(dataset) %>% summarise(median = sprintf("%.1f", round(median(rrf.10), 1)), mad = sprintf("%.2f", round(mad(rrf.10), 2)))

mad <- with(mad, paste0(median, " (", mad, ")"))


tabrrf10 <- rbind(tabrrf10, (c("median (MAD)", mad[c(2:4, 1, 5,6)])))
saveRDS(tabrrf10, file = "tables/tab4_rrf10.RDS")

print(xtable(tabrrf10, align = c("r", "r", rep("c", 6))), 
      include.rownames=FALSE, comment = FALSE, booktabs = TRUE, hline.after = c(0,7))



```

```{r}
# base_data <- results %>%
#   select(model, dataset, rrf.10) %>%
#   group_by(dataset) %>%
#   summarise(smean = mean(rrf.10, na.rm=TRUE),
#             sd = sd(rrf.10, na.rm=TRUE),
#             count = n()) %>%
#   mutate(se = sd/sqrt(count),
#          lower = lower_ci(smean, se, count),
#          upper = upper_ci(smean, se, count))


rrf_plot <- ggplot(base_data_rrf, aes(x=dataset, y = smean)) +
  geom_point(aes(x=dataset, y=smean), size = .5) +
  geom_errorbar(aes(ymin=lower, ymax=upper), width = .25) +
  labs(x = "Dataset", y = "RRF@10") +
  scale_y_continuous(breaks = seq(0,100,10), limits=c(0,100)) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.background = element_rect(fill = "white", size = 4, colour = "white"),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank(),
    # explicitly set the horizontal lines (or they will disappear too)
    panel.grid.major.x = element_line( size=.05, color="black" )
    ) 

rrf_plot

ggsave("figures/rrf_values.png", rrf_plot)
```

```{r}
# probeersel: alle metrics in 1 plot, met verschillende kleuren 
# lower, upper, smean, dataset 

plot_data <- bind_rows(list(ATD = base_data_atd, 'RRF@10'=base_data_rrf, 'WSS@95'=base_data_wss), .id = "Statistic")


full_plot <- ggplot(plot_data, aes(x=dataset, y = smean, color = Statistic)) +
  geom_point(aes(x=dataset, y=smean), size = .5) +
  geom_errorbar(aes(ymin=lower, ymax=upper), width = .25) +
  labs(x = "Dataset", y = "Performance") +
  scale_y_continuous(breaks = seq(0,100,10), limits=c(0,100)) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.background = element_rect(fill = "white", size = 4, colour = "white"),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank(),
    # explicitly set the horizontal lines (or they will disappear too)
    panel.grid.major.x = element_line( size=.05, color="black" )
    ) 
full_plot

full_plot <-ggplot(plot_data, aes(x=dataset, y=smean #color = dataset
                                  )) +
  geom_point(aes(x=dataset, y=smean), size = .5) +
  geom_errorbar(aes(ymin=lower, ymax=upper), width = .25) +
  labs(x = "Dataset", y = "Performance") +
  scale_y_continuous(breaks = seq(0,100,10), limits=c(0,100)) +
  coord_flip() +
  theme_bw() +
  theme(
    legend.background = element_rect(fill = "white", size = 4, colour = "white"),
    legend.position='None',
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank(),
    # explicitly set the horizontal lines (or they will disappear too)
    panel.grid.major.x = element_line( size=.05, color="black" )) +
  facet_grid(vars(Statistic))

full_plot 

ggsave("figures/statistics_plot.png", full_plot, width = 168, height =98 , units = "mm")
```


# References